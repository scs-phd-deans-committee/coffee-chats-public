{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_tsp6eFWCju-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import os\n",
    "from pprint import pprint\n",
    "import itertools\n",
    "import math "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5poubZqyUxKD"
   },
   "source": [
    "# Configuration Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qkZ3jcZOUq4F"
   },
   "outputs": [],
   "source": [
    "HOME_DIR = ''\n",
    "os.chdir(HOME_DIR)\n",
    "\n",
    "DATE_TAG = '12_12'     # responses for this week should be named \"responses_{DATE_TAG}\"\n",
    "CUTOFF = '2020/12/01'  # a date after last week's responses and before this week's responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsxIpJIBCjvD"
   },
   "source": [
    "# Load this week's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XSwciHo3CjvD",
    "outputId": "a86e2e15-bfb3-4a7a-c778-e121565cbf54"
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 100)\n",
    "\n",
    "df = pd.read_csv(f'data/responses/responses_{DATE_TAG}.csv',\n",
    "                 parse_dates=['Timestamp'])\n",
    "df = df[df['Timestamp'] > CUTOFF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0f74x0MHX-AE",
    "outputId": "d2987e40-38e5-462b-de8d-23f92752004b"
   },
   "outputs": [],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59Wta0ViCjvG",
    "outputId": "4808288b-f719-4ddc-a775-cced88743c35"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "ulBSh-zlhmSe",
    "outputId": "c6f53dda-fef9-4333-fadf-e2843be85c8a"
   },
   "outputs": [],
   "source": [
    "df = df.rename({\n",
    "    'Timestamp': 'timestamp',\n",
    "    'Username': 'email',\n",
    "    'Name': 'name',\n",
    "    'Pronouns': 'pronouns',\n",
    "    'SCS Department': 'department',\n",
    "    'What year are you in?': 'yr',\n",
    "    'What times would you be able to meet? (Pittsburgh time) [Morning]': 'morning_times',\n",
    "    'What times would you be able to meet? (Pittsburgh time) [Afternoon]': 'afternoon_times',\n",
    "    'What times would you be able to meet? (Pittsburgh time) [Evening]': 'evening_times',\n",
    "    'If none of the above times work for you, what time zone are you in? (ET, PT, etc.)': 'time_zone',\n",
    "    'Where would you want to be able to meet?': 'where_to_meet',\n",
    "    'How would you like to be matched?': 'group_size',\n",
    "    'What kind of interaction are you after this week?': 'interaction_type',\n",
    "    'Hobbies/Interests': 'hobbies',\n",
    "    'Hobby Categories': 'hobby_categories',\n",
    "    'Anything else you want us to know for matching purposes?': 'other_friends',\n",
    "    'Research topics/interests': 'research_interests', \n",
    "    'Topics': 'research_categories',\n",
    "    'Anything else you want us to know for matching purposes?.1': 'other_research',\n",
    "    'Would you like to be a mentor and/or mentee?': 'mentor_vs_mentee', \n",
    "    'Background': 'background',\n",
    "    'Cultural background and Identity': 'culture',\n",
    "    'Anything else you want us to know for matching purposes?.2': 'other_mentor',\n",
    "    'Anything else you want us to know for matching purposes?.3': 'other_random',\n",
    "    'Can we include your answers to *this form* in aggregate statistics that we publish? Regardless of your answer, we will never share your individual form answers with anyone.': 'consent',\n",
    "    'Can we include your answers to *previous coffee chat forms* in aggregate statistics that we publish? Regardless of your answer, we will never share your individual form answers with anyone.': 'conset_prev',\n",
    "}, axis=1)\n",
    "\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bs-7Rd7qCjvK",
    "outputId": "6e54d18d-c11d-4055-83a8-d1086efd520e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# breakdown of interaction types this week\n",
    "print(f'Total responses: {len(df)}')\n",
    "df.groupby('interaction_type').count()['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mhGjkP1WCjvU"
   },
   "source": [
    "# Load in previous matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5BWmJm6UCjvU",
    "outputId": "f1683758-2173-4312-d570-33b71ab7aee8"
   },
   "outputs": [],
   "source": [
    "prev_pairs = []\n",
    "\n",
    "for f in os.listdir('data/matches/'):\n",
    "    if f.startswith('matched_pairs_') and not f.endswith(f'_{DATE_TAG}.csv'):\n",
    "        previous_data_file = 'data/matches/' + f\n",
    "        print(previous_data_file)\n",
    "        prev_matches = pd.read_csv(previous_data_file)\n",
    "        print(len(prev_matches))\n",
    "        prev_matches = prev_matches[['Email 1', 'Email 2', 'Email 3 (if applicable)']]\n",
    "        prev_matches = prev_matches.values.tolist()\n",
    "\n",
    "        for m in prev_matches:\n",
    "            for combo in itertools.combinations(m, 2):\n",
    "                assert(len(combo) == 2)\n",
    "                if (type(combo[0]) == float and np.isnan(combo[0])) or (type(combo[1]) == float and np.isnan(combo[1])):\n",
    "                    continue\n",
    "                prev_pairs.append(combo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DkKEp2vlf-GS"
   },
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VfNQ9FPZgAIk"
   },
   "outputs": [],
   "source": [
    "# pre-processing\n",
    "\n",
    "def clean_val(val, none_val=''):\n",
    "    if (val is None) or (type(val) == float and np.isnan(val)):\n",
    "        return none_val\n",
    "    return val\n",
    "\n",
    "\n",
    "def combine_times(d):\n",
    "    times = list(['{} Morning'.format(t) for t in d['morning_times']])\n",
    "    times += list(['{} Afternoon'.format(t) for t in d['afternoon_times']])\n",
    "    times += list(['{} Evening'.format(t) for t in d['evening_times']])\n",
    "    return times\n",
    "\n",
    "\n",
    "list_fields = [\n",
    "    'department',\n",
    "    'morning_times',\n",
    "    'afternoon_times',\n",
    "    'evening_times',\n",
    "    'where_to_meet',\n",
    "    'hobby_categories',\n",
    "    'research_categories',\n",
    "    'culture'\n",
    "]\n",
    "\n",
    "\n",
    "def df_to_dicts(cohort_df, relevant_fields, custom_cleaners={}):  \n",
    "    # note: if using a custom cleaner, make sure it's not in list_fields\n",
    "    people = []\n",
    "    for (i, row) in cohort_df[relevant_fields].iterrows():\n",
    "        d = dict(zip(relevant_fields, row.tolist()))\n",
    "        for k in d:\n",
    "            if k in list_fields:\n",
    "                d[k] = [v for v in clean_val(d[k]).split(';') if len(v) > 0]\n",
    "            else:\n",
    "                val = clean_val(d[k])\n",
    "                if k in custom_cleaners:\n",
    "                    val = custom_cleaners[k](val)\n",
    "                d[k] = val\n",
    "        d['times'] = combine_times(d)  # combine morning, afternoon, and evening\n",
    "        people.append(d)\n",
    "    return people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gCPk-pw92tfN"
   },
   "outputs": [],
   "source": [
    "## scoring\n",
    "\n",
    "def get_general_match_score(p1, p2):  \n",
    "    \"\"\"Initial matching score. \n",
    "    \n",
    "    Based on previous pairs, timing, location, and group size.\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    reasons = []\n",
    "\n",
    "    # decrease score if previously met\n",
    "    if ((p1['email'], p2['email']) in prev_pairs) or ((p2['email'], p1['email']) in prev_pairs):\n",
    "        score -= 15\n",
    "    \n",
    "    # based on timing    \n",
    "    common_times = set(p1['times']).intersection(set(p2['times']))\n",
    "    if len(common_times) > 0:\n",
    "        score += 2\n",
    "        reasons.append(['common time', common_times])\n",
    "    \n",
    "    # based on location\n",
    "    wh1 = p1['where_to_meet']\n",
    "    wh2 = p2['where_to_meet']\n",
    "    if wh1 is None:\n",
    "        wh1 = ['Over Zoom', 'In-person in Pittsburgh (physically distant and outside)']\n",
    "    if wh2 is None:\n",
    "        wh2 = ['Over Zoom', 'In-person in Pittsburgh (physically distant and outside)']\n",
    "    common_place = set(wh1).intersection(set(wh2))\n",
    "    if len(common_place) > 0:\n",
    "        score += 1\n",
    "        if len(wh1) == 1 and len(wh2) == 1:\n",
    "            score += 0.5\n",
    "        reasons.append(['common place', common_place])\n",
    "    else:\n",
    "        score -= 3\n",
    "    \n",
    "    # based on group size\n",
    "    if (p1['group_size'] == 'In a pair') and (p2['group_size'] == 'In a pair'):\n",
    "        score += 2\n",
    "\n",
    "    return score, reasons\n",
    "\n",
    "\n",
    "def get_combo_scores(people, match_score_fn, topics_ct, \n",
    "                     triple_bonus_fn=None, quad_bonus_fn=None, \n",
    "                     compute_quads=False):\n",
    "    pair_scores = []\n",
    "    for (i, p1) in enumerate(people):\n",
    "        for (j, p2) in enumerate(people):\n",
    "            if not (i < j):\n",
    "                continue\n",
    "            \n",
    "            s, reasons = match_score_fn(p1, p2, topics_ct)\n",
    "            \n",
    "            if p1['group_size'] == 'In a group of 3-4' or p2['group_size'] == 'In a group of 3-4':\n",
    "                s -= 5\n",
    "            if p1['group_size'] == 'No preference' and p2['group_size'] == 'No preference':\n",
    "                s -= 1\n",
    "            \n",
    "            pair_scores.append([(i, j), s])\n",
    "\n",
    "    triple_scores = []\n",
    "    for (i, p1) in enumerate(people):\n",
    "        for (j, p2) in enumerate(people):\n",
    "            for (k, p3) in enumerate(people):\n",
    "                if not (i < j and j < k):\n",
    "                    continue\n",
    "\n",
    "                s12, reasons12 = match_score_fn(p1, p2, topics_ct)\n",
    "                s23, reasons23 = match_score_fn(p2, p3, topics_ct)\n",
    "                s13, reasons13 = match_score_fn(p1, p3, topics_ct)\n",
    "                s = (s12 + s23 + s13) / 2.5\n",
    "                \n",
    "                if triple_bonus_fn is not None:\n",
    "                    s += triple_bonus_fn(p1, p2, p3)\n",
    "\n",
    "                if 'In a pair' in set([p1['group_size'], p2['group_size'], p3['group_size']]):\n",
    "                    s -= 6\n",
    "                if 'In a group of 3-4' in set([p1['group_size'], p2['group_size'], p3['group_size']]):\n",
    "                    s += 2\n",
    "                \n",
    "                triple_scores.append([(i, j, k), s])\n",
    "\n",
    "    if not compute_quads:\n",
    "        return pair_scores + triple_scores\n",
    "\n",
    "    quad_scores = []\n",
    "    for (i, p1) in enumerate(people):\n",
    "        for (j, p2) in enumerate(people):\n",
    "            for (k, p3) in enumerate(people):\n",
    "                for (l, p4) in enumerate(people):\n",
    "                    if not (i < j and j < k and k < l):\n",
    "                        continue\n",
    "\n",
    "                    s12, reasons12 = match_score_fn(p1, p2, topics_ct)\n",
    "                    s13, reasons13 = match_score_fn(p1, p3, topics_ct)\n",
    "                    s14, reasons14 = match_score_fn(p1, p4, topics_ct)\n",
    "                    s23, reasons23 = match_score_fn(p2, p3, topics_ct)\n",
    "                    s24, reasons24 = match_score_fn(p2, p4, topics_ct)\n",
    "                    s34, reasons34 = match_score_fn(p3, p4, topics_ct)\n",
    "                    s = (s12 + s13 + s14 + s23 + s24 + s34) / 5\n",
    "                    \n",
    "                    if quad_bonus_fn is not None:\n",
    "                        s += quad_bonus_fn(p1, p2, p3, p4)\n",
    "\n",
    "                    if 'In a pair' in set([p1['group_size'], p2['group_size'], p3['group_size'], p4['group_size']]):\n",
    "                        s -= 6\n",
    "                    if 'In a group of 3-4' in set([p1['group_size'], p2['group_size'], p3['group_size'], p4['group_size']]):\n",
    "                        s += 2\n",
    "                    \n",
    "                    quad_scores.append([(i, j, k, l), s])\n",
    "    return pair_scores + triple_scores + quad_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptKvBBxbCjvY"
   },
   "source": [
    "# Mentorship Matching (supplemented w/ Random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "id": "e-1tTMHNCjvY",
    "outputId": "b45994be-167f-4ff0-eb1e-eaca57567ee9"
   },
   "outputs": [],
   "source": [
    "mentorship = df[df['interaction_type'] == 'PhD mentorship']\n",
    "\n",
    "pd.set_option('max_colwidth', 200)\n",
    "\n",
    "# look at special requests\n",
    "mentorship[['mentor_vs_mentee', 'department', 'yr', 'group_size', 'other_mentor', 'other_random']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JyaOzHkOCrzf",
    "outputId": "0eadfd6e-8a67-4c5d-a36c-31ef13813733"
   },
   "outputs": [],
   "source": [
    "# check whether we have enough mentors. otherwise, extract mentors from random\n",
    "\n",
    "mentees = mentorship[mentorship['mentor_vs_mentee'] == 'Mentee']\n",
    "mentors = mentorship[mentorship['mentor_vs_mentee'] == 'Mentor']\n",
    "\n",
    "print(f'{len(mentees)} mentees, {len(mentors)} mentors')\n",
    "\n",
    "def get_department_count(mdf):\n",
    "    m_dep = mdf.groupby('department').count()[['name']].rename({'name': 'ct'}, axis=1)\n",
    "    m_dep = m_dep.to_dict('index')\n",
    "    new_d = {}\n",
    "    for md in m_dep:\n",
    "        for m in md.split(';'):\n",
    "            new_d[m] = m_dep[md]['ct']\n",
    "    return new_d\n",
    "\n",
    "# get mapping of department to number of people\n",
    "mentee_dep = get_department_count(mentees)\n",
    "mentor_dep = get_department_count(mentors)\n",
    "\n",
    "# number of additional mentors needed per department\n",
    "scarcity = {}\n",
    "for dep in mentee_dep:\n",
    "    while mentor_dep.get(dep, 0) > 0:\n",
    "        mentor_dep[dep] -= 1\n",
    "        mentee_dep[dep] -= 1\n",
    "\n",
    "    if mentee_dep[dep] > 0:\n",
    "        scarcity[dep] = scarcity.get(dep, 0) + mentee_dep[dep]\n",
    "        \n",
    "print('Need more mentors in these departments:')\n",
    "pprint(scarcity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "id": "yQfS-FrSCG-z",
    "outputId": "c164658a-27da-468a-aad8-24d2435fb526"
   },
   "outputs": [],
   "source": [
    "random = df[df['interaction_type'].isin(['Random', 'Random/Other'])]\n",
    "\n",
    "# get potential mentors\n",
    "pot_m = random\n",
    "pot_m = pot_m[pot_m['yr'].replace({'6+': 6}).astype(int) > 1]\n",
    "pot_m = pot_m[pot_m['department'].isin(list(scarcity.keys()))]\n",
    "\n",
    "# look at special requests\n",
    "pot_m[['department', 'yr', 'group_size', 'other_mentor', 'other_random']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MFbqLypGCjvb"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kq97SvOpCjvg",
    "outputId": "b9f588c7-a516-46d7-ae98-94453ec99df2"
   },
   "outputs": [],
   "source": [
    "relevant_fields = [\n",
    "    'email', 'name', \n",
    "    'department', 'yr', 'background',\n",
    "    'morning_times', 'afternoon_times', 'evening_times', \n",
    "    'where_to_meet', \n",
    "    'group_size',\n",
    "    'mentor_vs_mentee',\n",
    "    'culture',\n",
    "    'other_mentor',\n",
    "    'other_random',\n",
    "]\n",
    "mentorship_combined = pd.concat([mentorship, pot_m], axis=0)\n",
    "mentorship_people = df_to_dicts(mentorship_combined, relevant_fields)  # list of dicts\n",
    "\n",
    "topics_ct = {}\n",
    "for p in mentorship_people:\n",
    "    for cat in p['culture'] + [p['background']]:\n",
    "        if len(cat) == 0:\n",
    "            continue\n",
    "        topics_ct[cat] = topics_ct.get(cat, 0) + 1\n",
    "    \n",
    "topics_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bw4mV1SwPdVS"
   },
   "outputs": [],
   "source": [
    "def get_mentorship_match_score(p1, p2, topics_ct):\n",
    "    score, reasons = get_general_match_score(p1, p2)\n",
    "    \n",
    "    # based on hobbies\n",
    "    topic1 = set(p1['culture'] + [p1['background']])\n",
    "    topic2 = set(p2['culture'] + [p2['background']])\n",
    "    common_topics = topic1.intersection(topic2)\n",
    "    reasons.append(['common topics', common_topics])\n",
    "    for ci in common_topics:\n",
    "        if len(ci) == 0:\n",
    "            continue\n",
    "        if topics_ct[ci] <= 4:  # if rare topic, increase score\n",
    "            score += 4\n",
    "        else:\n",
    "            score += 2\n",
    "    score += 2 * len(common_topics)\n",
    "\n",
    "    if set([p1['mentor_vs_mentee'], p2['mentor_vs_mentee']]) == set(['Mentee', 'Mentor']):\n",
    "        score += 15\n",
    "    \n",
    "    if not (p1['mentor_vs_mentee'] == 'Mentee' and p2['mentor_vs_mentee'] == 'Mentee'):\n",
    "        dep1 = set(p1['department'])\n",
    "        dep2 = set(p2['department'])\n",
    "        if len(dep1.intersection(dep2)) > 0:\n",
    "            score += 7\n",
    "        \n",
    "        mentee_p = p1 if p1['mentor_vs_mentee'] == 'Mentee' else p2\n",
    "        mentor_p = p2 if p1['mentor_vs_mentee'] == 'Mentee' else p1  # mentor is one that's not mentee\n",
    "\n",
    "        if mentor_p['yr'] > mentee_p['yr']:\n",
    "            score += 5\n",
    "\n",
    "    return score, reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qEmsElPPPddn",
    "outputId": "676945da-cd6b-4d5e-aa04-e6730d3f002f"
   },
   "outputs": [],
   "source": [
    "print(topics_ct)\n",
    "\n",
    "def mentorship_bonus(*args):\n",
    "    bonus = 0\n",
    "    roles = [r['mentor_vs_mentee'] for r in args]\n",
    "\n",
    "    role_cts = {}\n",
    "    for role in roles:\n",
    "        role_cts[role] = role_cts.get(role, 0) + 1\n",
    "    \n",
    "    # design choice to prefer 2 mentees in same group\n",
    "    if role_cts.get('Mentee', 0) > 1:\n",
    "        bonus += 3\n",
    "    \n",
    "        if role_cts.get('Mentor', 0) > 1:\n",
    "            bonus += 1\n",
    "    return bonus\n",
    "\n",
    "all_mentorship_scores = get_combo_scores(mentorship_people, \n",
    "                                         get_mentorship_match_score, \n",
    "                                         topics_ct, \n",
    "                                         triple_bonus_fn=mentorship_bonus,\n",
    "                                         quad_bonus_fn=mentorship_bonus,\n",
    "                                         compute_quads=True)\n",
    "all_mentorship_scores = list(reversed(sorted(all_mentorship_scores, key=lambda x: x[1])))\n",
    "print(len(all_mentorship_scores))\n",
    "all_mentorship_scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D69qXCqlCjvj"
   },
   "outputs": [],
   "source": [
    "mentorship_matches = []\n",
    "mentorship_matched_people = set([])\n",
    "for idx, s in all_mentorship_scores:\n",
    "    assert(len(idx) in [2, 3, 4])\n",
    "    \n",
    "    if len(mentorship_matched_people.intersection(set(list(idx)))) > 0:\n",
    "        continue\n",
    "        \n",
    "    st = '{}\\nscore: {}\\n\\n'.format(idx, s)\n",
    "    for (_, i) in enumerate(list(idx)):\n",
    "        mentorship_matched_people.add(i)\n",
    "        p = mentorship_people[i]\n",
    "        st += f\"\"\"\n",
    "          P{_}: {p['name']}\n",
    "          role: {p['mentor_vs_mentee']}\n",
    "          department, year: {p['department']}, {p['yr']}\n",
    "          topic: {p['culture'] + [p['background']]}\n",
    "          how: {p['group_size']}\n",
    "          other: {p['other_mentor'], p['other_random']}\\n\\n\"\"\"            \n",
    "    print(st)\n",
    "    mentorship_matches.append(idx)\n",
    "    if len(idx) == 2:\n",
    "        pprint(get_mentorship_match_score(mentorship_people[idx[0]], mentorship_people[idx[1]], topics_ct)[1])\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GmfN_DO0Rl9l",
    "outputId": "22afed0c-fa78-4cdc-a7f0-dc74755dc605"
   },
   "outputs": [],
   "source": [
    "print('Remaining unmatched mentors/mentees: ', list([mentorship_people[i] for i in range(len(mentorship_people)) if i not in mentorship_matched_people]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KbVRreLnJgen",
    "outputId": "a008c1c9-88a1-4e74-8edb-aeec6e00605b"
   },
   "outputs": [],
   "source": [
    "mentorship_group_emails = []\n",
    "for grp in mentorship_matches:\n",
    "    emails = list([mentorship_people[i]['email'] for i in grp])\n",
    "    mentorship_group_emails.append(emails)\n",
    "mentorship_group_emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N31tEiE9LW00"
   },
   "source": [
    "# Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "id": "k7Gi0mQPLdHN",
    "outputId": "085ad57c-a121-4eb8-8067-495e6f0ddfab"
   },
   "outputs": [],
   "source": [
    "researchers = df[df['interaction_type'] == 'Research topic']\n",
    "researchers[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a86HsppXLgmT",
    "outputId": "f3477800-a806-49b1-81a6-95e98a99d999"
   },
   "outputs": [],
   "source": [
    "relevant_fields = [\n",
    "    'email', 'name', \n",
    "    'morning_times', 'afternoon_times', 'evening_times', \n",
    "    'where_to_meet', \n",
    "    'group_size',\n",
    "    'research_interests', 'research_categories',\n",
    "    'other_research'\n",
    "]\n",
    "research_people = df_to_dicts(researchers, relevant_fields)  # list of dicts\n",
    "\n",
    "topics_ct = {}\n",
    "for p in research_people:\n",
    "    for cat in p['research_categories']:\n",
    "        if len(cat) == 0:\n",
    "            continue\n",
    "        topics_ct[cat] = topics_ct.get(cat, 0) + 1\n",
    "\n",
    "topics_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GTs5P6y8LhtN"
   },
   "outputs": [],
   "source": [
    "def get_research_match_score(p1, p2, topics_ct):\n",
    "    score, reasons = get_general_match_score(p1, p2)\n",
    "    \n",
    "    # based on hobbies\n",
    "    topic1 = set(p1['research_categories'])\n",
    "    topic2 = set(p2['research_categories'])\n",
    "    common_topics = topic1.intersection(topic2)\n",
    "    reasons.append(['common topics', common_topics])\n",
    "    for ci in common_topics:\n",
    "        if topics_ct[ci] <= 5:  # if rare topic, increase score\n",
    "            score += 4\n",
    "        else:\n",
    "            score += 2\n",
    "    score += 2 * len(common_topics)\n",
    "\n",
    "    return score, reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UNx-GCGeLogE",
    "outputId": "689fb42e-ff6c-4878-e335-b877a44fc085"
   },
   "outputs": [],
   "source": [
    "all_researchers_scores = get_combo_scores(research_people, get_research_match_score, topics_ct)\n",
    "all_researchers_scores = list(reversed(sorted(all_researchers_scores, key=lambda x: x[1])))\n",
    "print(len(all_researchers_scores))\n",
    "all_researchers_scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KuITjuoaLuih"
   },
   "outputs": [],
   "source": [
    "research_matches = []\n",
    "research_matched_people = set([])\n",
    "for idx, s in all_researchers_scores:\n",
    "    assert(len(idx) in [2, 3])\n",
    "    \n",
    "    if len(research_matched_people.intersection(set(list(idx)))) > 0:\n",
    "        continue\n",
    "        \n",
    "    st = '{}\\nscore: {}\\n\\n'.format(idx, s)\n",
    "    for (_, i) in enumerate(list(idx)):\n",
    "        research_matched_people.add(i)\n",
    "        p = research_people[i]\n",
    "        st += 'P{}: {}\\ntopic: {}\\nhow: {}\\nother: {}\\n\\n'.format(\n",
    "            _, p['name'], p['research_interests'], p['group_size'], p['other_research'])\n",
    "    print(st)\n",
    "    research_matches.append(idx)\n",
    "    if len(idx) == 2:\n",
    "        pprint(get_research_match_score(research_people[idx[0]], research_people[idx[1]], topics_ct)[1])\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T7oBkg7gLwUw",
    "outputId": "fa00a5ec-8b81-41f8-a0b9-fe3bac389a97"
   },
   "outputs": [],
   "source": [
    "print('Remaining unmatched researchers: ', list([research_people[i] for i in range(len(research_people)) if i not in research_matched_people]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FrjqaRK5KGII",
    "outputId": "9948149f-3c30-457d-d734-e5c5d67e4040"
   },
   "outputs": [],
   "source": [
    "research_group_emails = []\n",
    "for grp in research_matches:\n",
    "    emails = list([research_people[i]['email'] for i in grp])\n",
    "    research_group_emails.append(emails)\n",
    "research_group_emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wA2zOWthCjvm"
   },
   "source": [
    "# Friendship Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 734
    },
    "id": "KMaoEZddCjvm",
    "outputId": "29796dc4-ceff-4aa5-a0e4-f95a62576dff"
   },
   "outputs": [],
   "source": [
    "friends = df[df['interaction_type'] == 'Friendship outside of work']\n",
    "friends[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MGCTB-H45ODg"
   },
   "source": [
    "### Extract cleaner hobby tokens from freetext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZUxyWjVoCjvt"
   },
   "outputs": [],
   "source": [
    "def get_clean_hobbies(hobby_freetext):\n",
    "    hobbies = hobby_freetext.replace('\\n', ',').replace(':', ',').replace(';', ',')\n",
    "    hobbies = hobbies.translate(str.maketrans(string.punctuation.replace('-', ''), ',' * (len(string.punctuation) - 1), ''))\n",
    "    hobbies = hobbies.split(',')\n",
    "    hobs = [h.lower().strip() for h in hobbies]\n",
    "\n",
    "    hobby_lookup = {\n",
    "        'geopolitics': 'politics',\n",
    "        'foodie': 'food',\n",
    "        'movie buff': 'movies',\n",
    "        'painting': 'art',\n",
    "        'exploring cities': 'traveling',\n",
    "        'exploring': 'traveling',\n",
    "        'transit': 'traveling',\n",
    "        'geography': 'history',\n",
    "        'japanese language': 'languages',\n",
    "        'gaming': 'video games',\n",
    "        'playing music': 'music',\n",
    "        'physical fitness': 'fitness',\n",
    "        'exercise': 'fitness',\n",
    "        'swimming': 'fitness',\n",
    "        'super smash bros melee': 'video games',\n",
    "        'chess': 'board games',\n",
    "        'want to get involved in volunteering': 'volunteering',\n",
    "        'wine': 'alcohol',\n",
    "        'travel': 'traveling',\n",
    "        'FIRST': ['stem', 'robotics'],\n",
    "        'musicviolin': 'music',\n",
    "        'entrepreneurship': 'startups',\n",
    "        'philosophy': 'humanities',\n",
    "        'coffee': 'beverages',\n",
    "        'math': 'stem',\n",
    "        'roller skating': 'playing sports',\n",
    "        'reptiles': 'animals',\n",
    "        'visual art': 'art',\n",
    "        'economics': 'humanities',\n",
    "        'tech': 'stem',\n",
    "        'piano': 'music',\n",
    "        'card game': 'board games',\n",
    "        'algorithm': 'stem',\n",
    "        'learning languages': 'languages',\n",
    "        'classical music': 'music',\n",
    "        'reading history': 'history',\n",
    "        'ice skating': 'playing sports',\n",
    "        'practicing italian': 'languages',\n",
    "        'watching tv': 'tv',\n",
    "        'tv shows': 'tv',\n",
    "        'breweries': 'alcohol',\n",
    "        'wineries': 'alcohol',\n",
    "        'occasional visits adventure sports and theme parks': 'playing sports',\n",
    "        'watching movies': 'movies',\n",
    "        'singing': 'music',\n",
    "        'listening to podcasts and music': 'podcasts/audiobooks',\n",
    "        'diy handyman': 'diy',\n",
    "        'backpacking': 'outdoors',\n",
    "        'outdoor adventures': 'outdoors',\n",
    "        'guitar': 'music',\n",
    "        'surfing': 'playing sports',\n",
    "        'general banter': 'conversation',\n",
    "        'procrastinating by reading about procrastination': 'productivity',\n",
    "        'productivity hacks': 'productivity',\n",
    "        'cocktail making': 'alcohol',\n",
    "        'watching avatar on netflix': 'tv',\n",
    "        'action-adventure': 'movies',\n",
    "        'moviesmystery': 'movies',\n",
    "        'lazy cooking': 'cooking',\n",
    "        'violin': 'music',\n",
    "        'performance modelling': 'stem',\n",
    "        'cycling': 'biking',\n",
    "        'resource management': 'productivity',\n",
    "        'scheduling': 'productivity',\n",
    "        'networks': 'stem',\n",
    "        'and animal facts': 'animals',\n",
    "        'memes': 'comedy',\n",
    "        'musical instruments': 'music',\n",
    "        'social justice': 'volunteering',\n",
    "        'playing violin': 'music',\n",
    "        'vegetables': 'food',\n",
    "        'bread': 'food',\n",
    "        'tea': 'beverages',\n",
    "        'fermenting things': 'cooking',\n",
    "        'policy': 'politics',\n",
    "        'verification': 'stem',\n",
    "        'emacs': 'stem',\n",
    "        'systems': 'stem',\n",
    "        'photography': 'art',\n",
    "        'i play drums': 'music',\n",
    "        'climbing': 'climbing',\n",
    "        'drawing': 'art',\n",
    "        'running': 'running',\n",
    "        'jogging': 'running',\n",
    "        'learning about pittsburgh': 'pittsburgh',\n",
    "        'watching sports in quarantine': 'watching sports',\n",
    "        'ultimate frisbee': 'playing sports',\n",
    "        'want to start biking': 'biking',\n",
    "        'politics': 'politics',\n",
    "        'playing music': 'music',\n",
    "        'violin': 'music',\n",
    "        'whiskey': 'alcohol',\n",
    "        'adventure sports': 'playing sports',\n",
    "        'stand-up': 'comedy',\n",
    "        'tv': 'tv',\n",
    "        'films': 'movies',\n",
    "        'improv': ['improv', 'comedy'],\n",
    "        'pets': 'animals',\n",
    "        'video games': 'video games',\n",
    "        'sports': 'watching sports',\n",
    "        'gbbo': ['baking', 'cooking'],\n",
    "        'npr one': 'podcasts/audiobooks',\n",
    "        'audiobooks': 'podcasts/audiobooks',\n",
    "        'rock climbing': ['climbing', 'playing sports'],\n",
    "        'badminton': 'playing sports',  # week 8/28\n",
    "        'mystery': 'mystery',\n",
    "        'currently watching legend of korra on netflix': 'tv',\n",
    "        'formula1': 'watching sports',\n",
    "        'playing tennis': ['tennis', 'playing sports'],\n",
    "        'things to do in pittsburgh': 'pittsburgh',\n",
    "        'podcasts': 'podcasts/audiobooks',\n",
    "        'watching musicals': ['musicals', 'music'],\n",
    "        'reading books': 'reading',\n",
    "        'fiction stories and things about grammar':'reading',\n",
    "        'eating ice cream':'food',\n",
    "        'writing':'reading',\n",
    "        'scrolling through twitter':'twitter',\n",
    "        'space':'stem',\n",
    "        'rocks':'stem',\n",
    "        'roofs':'diy',\n",
    "        'the great british bake off':['baking', 'cooking'],\n",
    "        'marvel':'tv',\n",
    "        'agents of shield':'tv',\n",
    "        'gym':'fitness',\n",
    "        'bouldering':'climbing',\n",
    "        'finding creative ways to exercise in quarantine':'fitness',\n",
    "        'sci-fi': ['sci-fi', 'stem'],\n",
    "        'basketball': 'playing sports',\n",
    "        'jazz rnb and foreign music': 'music',\n",
    "        'books': 'reading',\n",
    "        'learning about pittsburgh area': 'pittsburgh',\n",
    "        'dinosaurs': 'animals',\n",
    "        'cooking and experimenting with different cuisines': 'cooking',\n",
    "        'taking walks': 'outdoors',\n",
    "        'general banter and discussions': 'conversation',\n",
    "        'textiles': 'diy',\n",
    "        'knitting': 'diy',\n",
    "        'crocheting': 'diy',\n",
    "        'sewing': 'diy',\n",
    "        'mechanical engineering': 'stem',\n",
    "        'experimental music': 'music',\n",
    "        'listening to music and podcasts': 'podcasts/audiobooks',\n",
    "        'white water rafting': 'outdoors',\n",
    "        'mentoring others': 'volunteering',\n",
    "        'advocating for social justice': 'volunteering',\n",
    "        'skiing': 'playing sports',\n",
    "        'snowboarding': 'playing sports',\n",
    "        'outdoor activities': 'outdoors',\n",
    "        'language learning': 'languages',\n",
    "        'digital art': 'art',\n",
    "        'christian faith': 'christian',\n",
    "        'board game': 'board games',\n",
    "        'go': 'board games',\n",
    "        'about pittsburgh area': 'pittsburgh',\n",
    "        'watching legend of korra on netflix': 'tv',\n",
    "        'tennis': ['tennis', 'playing sports'],\n",
    "        'soccer': ['soccer', 'playing sports', 'watching sports'],\n",
    "        'walking': ['pittsburgh', 'hiking'],\n",
    "        'hiking': ['hiking', 'outdoors'],\n",
    "        'camping': ['hiking', 'outdoors'],\n",
    "        'videogames': 'video games',\n",
    "        'outer space': 'stem',\n",
    "        'robotics': ['stem', 'robotics'],\n",
    "        'grammar': ['languages', 'reading'],\n",
    "        'musicals': ['musicals', 'music'],\n",
    "        'science fiction': 'sci-fi',\n",
    "        'vinyl records': 'music',\n",
    "        'fitness': ['fitness', 'playing sports'],\n",
    "        'web serial fiction': ['reading', 'fiction', 'anime'],\n",
    "        'anime': 'anime',\n",
    "        'walking in parks': ['walking', 'pittsburgh', 'outdoors'],\n",
    "        'bunny watching': ['outdoors', 'pittsburgh'],\n",
    "        'recreational programming': 'stem',\n",
    "        'spanish': ['spanish', 'languages'],\n",
    "        'queer cinema': ['movies', 'lgbtq'],\n",
    "        'fantasy books': ['fantasy', 'reading'],\n",
    "        'dei': ['volunteering', 'lgbtq'],\n",
    "        'comedy improv': ['improv', 'comedy'],\n",
    "        'origami': ['origami', 'art'],\n",
    "        'ping-pong': ['ping-pong', 'playing sports'],\n",
    "        'general discussions': 'conversation',\n",
    "        'dance': ['dance', 'music'],\n",
    "        'story books': ['reading'],\n",
    "        'light-hearted discussions': 'conversation',\n",
    "        'trivia': ['trivia', 'board games'],\n",
    "        'exploration of pittsburgh': ['pittsburgh'],\n",
    "        'frisbee': ['frisbee', 'watching sports']\n",
    "    }\n",
    "    \n",
    "    stopwords = [\n",
    "        'academic',\n",
    "        'currently',\n",
    "        'esp',\n",
    "        'learning',\n",
    "        'etc',\n",
    "    ]\n",
    "    clean = []\n",
    "    for h in hobs:\n",
    "        h = h.strip().lower()\n",
    "        for s in stopwords:\n",
    "            h = h.replace(s, '')   \n",
    "            h = h.strip()\n",
    "        \n",
    "        if len(h) == 0:\n",
    "            continue\n",
    "            \n",
    "        h = hobby_lookup.get(h, h)\n",
    "        if type(h) == str:\n",
    "            clean.append(h)\n",
    "        else:\n",
    "            assert(type(h) == list)            \n",
    "            clean += h\n",
    "            \n",
    "        \n",
    "    clean = [c for c in clean if len(c) > 0]\n",
    "    clean = list(set(clean))\n",
    "    return clean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZxVcn6AI5YP3"
   },
   "source": [
    "### Compute friendship scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jSTCb21oCjvp",
    "outputId": "2430c171-a2df-4312-8bdf-30e4bde118e9"
   },
   "outputs": [],
   "source": [
    "relevant_fields = [\n",
    "    'email', 'name', \n",
    "    'morning_times', 'afternoon_times', 'evening_times', \n",
    "    'where_to_meet', \n",
    "    'group_size',\n",
    "    'hobbies', \n",
    "    'hobby_categories',\n",
    "    'other_friends'\n",
    "]\n",
    "friend_people = df_to_dicts(friends, relevant_fields, custom_cleaners={'hobbies': get_clean_hobbies})  # list of dicts\n",
    "friend_people[0]\n",
    "topics_ct = {}\n",
    "for p in friend_people:\n",
    "    for cat in (p['hobbies'] + p['hobby_categories']):\n",
    "        if len(cat) == 0:\n",
    "            continue\n",
    "        topics_ct[cat] = topics_ct.get(cat, 0) + 1\n",
    "\n",
    "topics_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f6M4WhwaCZjp"
   },
   "outputs": [],
   "source": [
    "def get_friendship_match_score(p1, p2, topics_ct):\n",
    "    score, reasons = get_general_match_score(p1, p2)\n",
    "    \n",
    "    # based on hobbies\n",
    "    topic1 = set(p1['hobbies'] + p1['hobby_categories'])\n",
    "    topic2 = set(p2['hobbies'] + p2['hobby_categories'])\n",
    "    common_topics = topic1.intersection(topic2)\n",
    "    reasons.append(['common topics', common_topics])\n",
    "    for ci in common_topics:\n",
    "        if topics_ct[ci] <= 5:  # if rare topic, increase score\n",
    "            score += 4\n",
    "        else:\n",
    "            score += 2\n",
    "    score += 2 * len(common_topics)\n",
    "\n",
    "    return score, reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UA6LUEHxCmT6"
   },
   "outputs": [],
   "source": [
    "all_friend_scores = get_combo_scores(friend_people, get_friendship_match_score, topics_ct)\n",
    "all_friend_scores = list(reversed(sorted(all_friend_scores, key=lambda x: x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d8yQ_JL-Csx6",
    "outputId": "07dd3a79-0d6f-468a-d686-281fcb1e7da0"
   },
   "outputs": [],
   "source": [
    "friend_matches = []\n",
    "friend_matched_people = set([])\n",
    "for idx, s in all_friend_scores:\n",
    "    assert(len(idx) in [2, 3])\n",
    "    \n",
    "    if len(friend_matched_people.intersection(set(list(idx)))) > 0:\n",
    "        continue\n",
    "        \n",
    "    st = '{}\\nscore: {}\\n\\n'.format(idx, s)\n",
    "    for (_, i) in enumerate(list(idx)):\n",
    "        friend_matched_people.add(i)\n",
    "        p = friend_people[i]\n",
    "        st += 'P{}: {}\\ntopic: {}\\nhow: {}\\nother: {}\\n\\n'.format(\n",
    "            _, p['name'], p['hobbies'] + p['hobby_categories'], p['group_size'], p['other_friends'])\n",
    "    print(st)\n",
    "    friend_matches.append(idx)\n",
    "    if len(idx) == 2:\n",
    "        pprint(get_friendship_match_score(friend_people[idx[0]], friend_people[idx[1]], topics_ct)[1])\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hm8rvslOCs3a",
    "outputId": "24e7e1da-7d04-4a55-b710-e94c91fd711c"
   },
   "outputs": [],
   "source": [
    "print('Remaining unmatched friends: ', list([friend_people[i] for i in range(len(friend_people)) if i not in friend_matched_people]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5AuWOjiNKVuw",
    "outputId": "eebf959c-ce8f-4578-ffdf-8e539cb6d21e"
   },
   "outputs": [],
   "source": [
    "friend_group_emails = []\n",
    "for grp in friend_matches:\n",
    "    emails = list([friend_people[i]['email'] for i in grp])\n",
    "    friend_group_emails.append(emails)\n",
    "friend_group_emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpTUi1xNHDFX"
   },
   "source": [
    "# Final matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NYcVXgUVHB9i",
    "outputId": "afe37bcd-eb93-4e39-ce4d-0ea7aac703ef"
   },
   "outputs": [],
   "source": [
    "matches = mentorship_group_emails + research_group_emails + friend_group_emails\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0iMnch8sHCYH",
    "outputId": "503b999a-c5b9-4de3-e12e-c0853c4bf9cc"
   },
   "outputs": [],
   "source": [
    "# get the remaining unmatched people\n",
    "pd.set_option('max_colwidth', 500)\n",
    "pd.set_option('display.width', 20000)\n",
    "\n",
    "\n",
    "def combine_other_cols(row):\n",
    "    friends = clean_val(row['other_friends'])\n",
    "    research = clean_val(row['other_research'])\n",
    "    mentorship = clean_val(row['other_mentor'])\n",
    "    random = clean_val(row['other_random'])\n",
    "    other = ''.join([friends, research, mentorship, random])\n",
    "    return other\n",
    "\n",
    "tempdf = df.set_index('email')\n",
    "for grp in matches:\n",
    "    grpdf = tempdf.loc[grp, :].reset_index().set_index('name')\n",
    "    grpdf['other'] = grpdf.apply(combine_other_cols, axis=1)\n",
    "    grpdf = grpdf\n",
    "    print('Other comments:')\n",
    "    print(grpdf['other'])\n",
    "    print('')\n",
    "    print(grpdf[['email', 'interaction_type', 'department', 'yr', 'pronouns', 'group_size']])\n",
    "    print('------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "44JvWC1ww9tc"
   },
   "outputs": [],
   "source": [
    "# manual adjustments based on \"other\" field\n",
    "# (copy/paste the full matches list and make adjustments manually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U-cvLz9ovTEj",
    "outputId": "9fca46b0-b7ee-42e3-9d88-df75402dddc1"
   },
   "outputs": [],
   "source": [
    "# look at remaining unmatched\n",
    "matched_email_set = []\n",
    "for grp in matches:\n",
    "    matched_email_set += grp\n",
    "matched_email_set = set(matched_email_set)\n",
    "\n",
    "remaining = df[~df['email'].isin(matched_email_set)]\n",
    "print(len(remaining))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vOss44P-0YUZ"
   },
   "outputs": [],
   "source": [
    "relevant_fields = [\n",
    "    'email', 'name', \n",
    "    'morning_times', 'afternoon_times', 'evening_times', \n",
    "    'where_to_meet', \n",
    "    'group_size',\n",
    "    'other_mentor',\n",
    "    'other_research',\n",
    "    'other_friends',\n",
    "    'other_random'\n",
    "]\n",
    "remaining_people = df_to_dicts(remaining, relevant_fields)  # list of dicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tzl1ixw4vTMP",
    "outputId": "942e43d4-4afd-4691-c2b0-51017580cbf3"
   },
   "outputs": [],
   "source": [
    "all_remaining_scores = get_combo_scores(\n",
    "    remaining_people, lambda x, y, z: get_general_match_score(x, y), {})\n",
    "all_remaining_scores = list(reversed(sorted(all_remaining_scores, key=lambda x: x[1])))\n",
    "print(len(all_remaining_scores))\n",
    "all_remaining_scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R1oeyUBP28KX",
    "outputId": "b7be09d3-653c-4338-ed39-bb6a297d205e"
   },
   "outputs": [],
   "source": [
    "remaining_matches = []\n",
    "remaining_matched_people = set([])\n",
    "for idx, s in all_remaining_scores:\n",
    "    assert(len(idx) in [2, 3])\n",
    "    \n",
    "    if len(remaining_matched_people.intersection(set(list(idx)))) > 0:\n",
    "        continue\n",
    "        \n",
    "    st = '{}\\nscore: {}\\n\\n'.format(idx, s)\n",
    "    for (_, i) in enumerate(list(idx)):\n",
    "        remaining_matched_people.add(i)\n",
    "        p = remaining_people[i]\n",
    "        st += 'P{}: {}\\nhow: {}\\nother: {}\\n\\n'.format(\n",
    "            _, p['name'], p['group_size'], p['other_random'])\n",
    "    print(st)\n",
    "    remaining_matches.append(idx)\n",
    "    if len(idx) == 2:\n",
    "        pprint(get_general_match_score(remaining_people[idx[0]], remaining_people[idx[1]])[1])\n",
    "    print('------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WztSyGceA7Rv",
    "outputId": "61cc3dd3-3e9f-4787-891d-f35d978c3c3c"
   },
   "outputs": [],
   "source": [
    "print('Remaining unmatched: ', list([remaining_people[i] for i in range(len(remaining_people)) if i not in remaining_matched_people]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gqSr-lCzA7eh"
   },
   "outputs": [],
   "source": [
    "remaining_group_emails = []\n",
    "for grp in remaining_matches:\n",
    "    emails = list([remaining_people[i]['email'] for i in grp])\n",
    "    remaining_group_emails.append(emails)\n",
    "remaining_group_emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zwgJiUPTAHyC",
    "outputId": "88c21aba-b674-4cbc-cb74-7257df587a2c"
   },
   "outputs": [],
   "source": [
    "final_matches = mentorship_group_emails + research_group_emails + friend_group_emails + remaining_group_emails\n",
    "print(sum([len(l) for l in final_matches]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "plIlUtGKBJNe",
    "outputId": "6fb23958-cf7c-44fc-ea9a-b13edb83a807"
   },
   "outputs": [],
   "source": [
    "print('============================ FINAL MATCHES ============================')\n",
    "tempdf = df.set_index('email')\n",
    "for grp in final_matches:\n",
    "    grpdf = tempdf.loc[grp, :].reset_index().set_index('name')\n",
    "    grpdf['other'] = grpdf.apply(combine_other_cols, axis=1)\n",
    "    grpdf = grpdf\n",
    "    print('Other comments:')\n",
    "    print(grpdf['other'])\n",
    "    print('')\n",
    "    print(grpdf[['email', 'interaction_type', 'department', 'yr', 'pronouns', 'group_size']])\n",
    "    print('------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2DZpZVqvvRCi"
   },
   "source": [
    "# Export matches to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "zuu8MeBlCjwV",
    "outputId": "e84777c3-e095-4900-a9ac-68e23cfb6f3c"
   },
   "outputs": [],
   "source": [
    "e_dict = {}\n",
    "for grp in final_matches:\n",
    "    for i in range(4):\n",
    "        if i <= len(grp) - 1:\n",
    "            e_dict[i] = e_dict.get(i, []) + [grp[i]]\n",
    "        else:\n",
    "            e_dict[i] = e_dict.get(i, []) + [np.nan]\n",
    "    \n",
    "all_groups = pd.DataFrame({\n",
    "    'Email 1': e_dict[0],\n",
    "    'Email 2': e_dict[1],\n",
    "    'Email 3 (if applicable)': e_dict[2],\n",
    "    'Email 4 (if applicable)': e_dict[3],\n",
    "})\n",
    "\n",
    "assert(len(df) == all_groups.notna().sum().sum())\n",
    "\n",
    "all_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s2s7AOc7Cjwe",
    "outputId": "ff22d664-6547-4060-9617-3bf23430dfa6"
   },
   "outputs": [],
   "source": [
    "save_path = f'data/matches/matched_pairs_{DATE_TAG}.csv'\n",
    "if not os.path.exists(save_path):\n",
    "    all_groups.to_csv(save_path, index=False)\n",
    "    print('saved!')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "mhGjkP1WCjvU",
    "DkKEp2vlf-GS",
    "wA2zOWthCjvm",
    "MGCTB-H45ODg"
   ],
   "name": "coffee_match_algorithm.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
